{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data: F1 Variation with sample size (at each mixture distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "# 50-50 Accuracy\n",
    "# a = [0.538, 0.589, 0.76, 0.823, 0.835, 0.83, 0.834, 0.84, 0.84, 0.84, 0.84]\n",
    "# f1A = [0.537, 0.602, 0.754, 0.835, 0.846, 0.822, 0.819, 0.849, 0.85, 0.85, 0.849]\n",
    "# f1B = [0.517, 0.564, 0.761, 0.811, 0.822, 0.836, 0.845, 0.83, 0.83, 0.83, 0.83]\n",
    "# yerr_a = [0.03059412, 0.03139218, 0.03273618, 0.009, 0.005, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 20-80 Accuracy\n",
    "a = [0.619, 0.611, 0.767, 0.849, 0.9, 0.908, 0.91, 0.91, 0.919, 0.911, 0.91]\n",
    "f1A = [0.728, 0.722, 0.845, 0.901, 0.937, 0.943, 0.948, 0.95, 0.95, 0.95, 0.95]\n",
    "f1B = [0.348, 0.355, 0.527, 0.665, 0.725, 0.747, 0.75, 0.75, 0.756, 0.749, 0.742]\n",
    "yerr_a = [0.05393515, 0.06064297, 0.03626123, 0.03718675, 0.00894427, 0.004, 0, 0, 0.003, 0.003, 0]\n",
    "\n",
    "# 35-65 Accuracy\n",
    "# a = [0.569, 0.622, 0.771, 0.847, 0.861, 0.869, 0.87, 0.869, 0.868, 0.87, 0.87]\n",
    "# f1A = [0.647, 0.696, 0.827, 0.887, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.91]\n",
    "# f1B = [0.43, 0.482, 0.654, 0.765, 0.779, 0.79, 0.798, 0.79, 0.789, 0.79, 0.79]\n",
    "# yerr_a = [0.05579514, 0.04717513, 0.04657252, 0.01004988, 3.00E-03, 3.00E-03, 1.11E-16, 3.00E-03, 4.00E-03, 1.11E-16, 0]\n",
    "\n",
    "x = [100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "plt.errorbar(x, a, yerr=yerr_a, linestyle='-', marker='o', color='steelblue', linewidth=2, markersize=5, label='Accuracy')\n",
    "plt.errorbar(x, f1A, color='indianred', marker='o', linestyle='--', linewidth=2, markersize=5, label='F1 (Component 1)')\n",
    "plt.errorbar(x, f1B, color='gray', marker='o', linestyle='--', linewidth=2, markersize=5, label='F1 (Component 2)')\n",
    "\n",
    "# plt.xticks(x, ['100', '', '1000', '', '2000', '', '3000', '', '4000', '', '5000']) #, [\"1K\",\"2K\", \"5K\", \"10K\"])\n",
    "plt.xticks(x, ['100', '', '1K', '', '2K','', '3K','', '4K', '', '5K'], fontsize=15, rotation=0)\n",
    "plt.xlabel('# samples', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim(0.3, 1.0)\n",
    "# matplotlib.rcParams['figure.figsize'] = 4, 4\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"newsep_2080\")\n",
    "# plt.savefig(\"newsep_5050\")\n",
    "# plt.savefig(\"newsep_3565\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data: MAE Variation with sample size (at each mixture distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "\n",
    "# 50-50 REC\n",
    "# a = [0.37074579, 0.25019493, 0.17404112, 0.12540508, 0.10128784, 0.09072607, 0.07849716, 0.07209409, 0.06757301, 0.06547084, 0.06311453]\n",
    "# b = [0.3949215, 0.24545285, 0.15568542, 0.10752383, 0.0933878, 0.08378726, 0.07491487, 0.06884225, 0.06643143, 0.06250859, 0.05921113]\n",
    "# c = [0.06062301, 0.02945277, 0.02348285, 0.0133709, 0.00942099, 0.00148567, 0.00246742, 0.0028287, 0.00585847, 0.00692459, 0.0053351]\n",
    "# yerr_a =[0.01559338, 0.01229178, 0.02463468, 0.00453263, 0.00251584, 0.00138803, 0.00236395, 0.00088981, 0.00041529, 0.00024523, 0.00024458]\n",
    "# yerr_b = [0.01125925, 0.02007671, 0.02983395, 0.00334533, 0.00143176, 0.00083398, 0.0016343, 0.00044455, 0.00027153, 0.00010729, 0.00015296]\n",
    "# yerr_c = [0.03342509, 0.03328124, 0.02947875, 0.00855437, 0.00197116, 0.00143394, 0.00122095, 0.00206881, 0.0015377, 0.00163429, 0.0023901]\n",
    "\n",
    "\n",
    "# 20-80 REC\n",
    "a = [0.38725599, 0.3076971, 0.24145477, 0.18859934, 0.15822143, 0.13764647, 0.12451263, 0.11706931, 0.10963067, 0.10454634, 0.09982226]\n",
    "b = [0.3575607, 0.21797727, 0.14646918, 0.10859049, 0.08432286, 0.07281996, 0.0652692, 0.0592536, 0.05621151, 0.05286894, 0.05054079]\n",
    "c =[0.25596714, 0.26309091, 0.15032923, 0.0824454, 0.02617578, 0.01671644, 0.00770426, 0.0021292, 0.00423743, 0.00638563, 0.00403792]\n",
    "yerr_a= [0.01062006, 0.01490311, 0.02031074, 0.02706351, 0.00430746, 0.00326909, 0.00191078, 0.0013886, 0.00086065, 0.00088548, 0.00074231]\n",
    "yerr_b= [0.01349547, 0.01082175, 0.02035687, 0.02351415, 0.00387934, 0.00231865, 0.0005127, 0.00030366, 0.00020685, 0.00022859, 0.00023127]\n",
    "yerr_c=[0.04526637, 0.04038411, 0.08177962, 0.07846018, 0.01594264, 0.00552713, 0.00410155, 0.00133193, 0.00092739, 0.00084702, 0.00175291]\n",
    "\n",
    "\n",
    "# 35-65 REC\n",
    "# a= [0.38730426, 0.29005627, 0.20453674, 0.14857088, 0.12417421, 0.11013571, 0.09489955, 0.08761794, 0.08140841, 0.07595319, 0.07595319]\n",
    "# b=[0.37721129, 0.22732048, 0.14089289, 0.10126032, 0.08339687, 0.07541356, 0.06815356, 0.06213098, 0.05815313, 0.05422041, 0.05422041]\n",
    "# c= [0.14450361, 0.0927384, 0.03495736, 0.01304002, 0.00343374, 0.00311035, 0.00811258, 0.0015987, 0.00518599, 0.00695579, 0.00695579]\n",
    "# yerr_a = [0.01531402, 0.01804096, 0.01839811, 0.00531005, 0.0023592, 0.00128358, 0.00104922, 0.00045345, 0.00102119, 0.00018216, 0.00018216]\n",
    "# yerr_b = [0.02399086, 0.02056504, 0.01450604, 0.00294091, 0.00067655, 0.00071754, 0.00049323, 0.00038846, 0.00048446, 0.00019417, 0.00019417]\n",
    "# yerr_c =[0.06133387, 0.05560605, 0.03764683, 0.00486948, 0.00239576, 0.00256609, 0.00168882, 0.0012212, 0.00238907, 0.00149278, 0.00149278]\n",
    "\n",
    "\n",
    "x = [100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "plt.errorbar(x, a, yerr=yerr_a, linestyle='-', marker='o', color='steelblue', linewidth=2, markersize=5, label='MAE Edges (Component 1)')\n",
    "plt.errorbar(x, b, yerr=yerr_b, color='indianred', marker='o', linestyle='-', linewidth=2, markersize=5, label='MAE Edges (Component 2)')\n",
    "plt.errorbar(x, c, yerr=yerr_c, color='gray', marker='o', linestyle='--', linewidth=2, markersize=5, label='MAE Mixture Weights')\n",
    "\n",
    "plt.xticks(x, ['100', '', '1K', '', '2K', '', '3K', '', '4K', '', '5K'], fontsize=15, rotation=0) #, [\"1K\",\"2K\", \"5K\", \"10K\"])\n",
    "plt.yticks(np.arange(0, 11, 1.0)*0.1)\n",
    "plt.xlabel('# Samples', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim(0.0, 0.4)\n",
    "# plt.ylabel('Training time (min) \\n', fontsize=15)\n",
    "plt.legend(loc='upper right', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"newrec_2080\")\n",
    "# plt.savefig(\"newrec_5050\")\n",
    "# plt.savefig(\"newrec_3565\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention analysis (Edge intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors as mcolors\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "mpl.rcParams['xtick.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 15\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_groups = 5\n",
    "\n",
    "means_oursgcn = [209.948] * n_groups\n",
    "means_ours = [210.464, 208.872, 206.496, 206.836, 205.196]\n",
    "means_linear = [193.844, 188.372, 169.164, 158.18, 105.728]\n",
    "\n",
    "# means_oursgcn = [100.7, 100.7, 100.7, 100.7]  # [60.293800, 90.099400, 99.163800, 109.7248, 147.251000]\n",
    "# means_ours = [91.08, 92.1, 87.78, 88.76] # [27.4858, 45.2956, 60.1078, 81.3892, 133.9648]\n",
    "# means_linear = [89.52, 88.1, 85.32, 82.92] # [71.647600, 91.751800, 102.42420, 109.07100, 146.83020] # ('MAE:', 3.799) - check for singleton seeds\n",
    "# means_logistic = [66.8156, 89.11, 98.02, 105.58, 160.19] # TODO (MAE: 2.691)\n",
    "# means_random = [28.262400,47.580000,61.714000,74.498800,128.902000]\n",
    "\n",
    "yerr_oursgcn = [19.792354483486797/1.5] * n_groups\n",
    "yerr_ours = np.array([18.858014317525587, 19.53252712784498, 18.270686467672746, 20.974105558998218, 19.18096931857199])/1.5\n",
    "yerr_linear = np.array([19.94280983211744, 19.5491589588913, 18.975170723869653, 12.94, 10.28659399412653])/1.5\n",
    "\n",
    "# yerr_logistic = [0.627607, 0.501393, 0.458658, 0.453951, 0.3805]\n",
    "# yerr_random = [0.968185,0.999080,0.985040,0.945063,0.655020]\n",
    " \n",
    "# create plot\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "opacity = 1.0 #  0.8\n",
    " \n",
    "rects1 = plt.bar(index, means_oursgcn, bar_width,\n",
    "yerr = yerr_oursgcn,\n",
    "alpha=opacity,\n",
    "color='steelblue',\n",
    "label='Without Intervention')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_ours, bar_width,\n",
    "yerr = yerr_ours,\n",
    "alpha=opacity,\n",
    "color=colors[\"indianred\"],\n",
    "label='Random Intervention')\n",
    " \n",
    "rects3 = plt.bar(index + 2*bar_width, means_linear, bar_width,\n",
    "yerr = yerr_linear,\n",
    "alpha=opacity,\n",
    "color=\"gray\",\n",
    "label='MIC Intervention')\n",
    "    \n",
    "# rects4 = plt.bar(index + 3*bar_width, means_logistic, bar_width,\n",
    "# yerr = yerr_logistic,\n",
    "# alpha=opacity*0.5,\n",
    "# color=\"gray\",\n",
    "# label='Constrained Logistic')\n",
    "\n",
    "# rects5 = plt.bar(index + 4*bar_width, means_random, bar_width,\n",
    "# yerr = yerr_random,\n",
    "# alpha=opacity,\n",
    "# color=colors[\"indianred\"],\n",
    "# label='Random')\n",
    "\n",
    "\n",
    "plt.xlabel('K (# edges removed)', fontsize=15)\n",
    "plt.ylabel('Expected influence $\\sigma(s)$', fontsize=15)\n",
    "# plt.title('Influence maximization', fontsize=15)\n",
    "plt.xticks(index + bar_width, ('20', '50', '100', '250', '500'))\n",
    "plt.legend(fontsize=12, loc='lower left')\n",
    " \n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"newkwon_edge_inter.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention analysis (Node intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train_labels = np.loadtxt(\"mic_code/datasets/twitter_ma/labels.txt\")\n",
    "train_labels = np.loadtxt(\"mic_code/datasets/kwon/labels.txt\")\n",
    "def _read_cascades_file(cascades_filename):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    cascades : list(np.array((None, 2)))\n",
    "        list of user_str, timestamp array (one array per cascade)\n",
    "    \"\"\"\n",
    "    f = open(cascades_filename, \"r\")\n",
    "    cascades = []\n",
    "    for line in f.readlines():\n",
    "        u_t = line.strip(\"\\n\").split(\",\")\n",
    "        u = list(map(str, u_t[0::2]))  # string\n",
    "        t = list(map(float, u_t[1::2]))  # float\n",
    "        cascade = np.vstack([u, t]).transpose()\n",
    "        cascades.append(cascade)\n",
    "    f.close()\n",
    "    return cascades\n",
    "train_cascades = _read_cascades_file(\"mic_code/datasets/kwon/cascades.txt\")\n",
    "# train_cascades = _read_cascades_file(\"mic_code/datasets/twitter_ma/cascades.txt\")\n",
    "print(len(train_cascades), len(train_labels))\n",
    "\n",
    "true_cascades = np.array(train_cascades)[train_labels==0]\n",
    "fake_cascades = np.array(train_cascades)[train_labels == 1]\n",
    "print(len(true_cascades), len(fake_cascades))\n",
    "\n",
    "# --------------\n",
    "u_f = {}\n",
    "for cas in fake_cascades:\n",
    "    for u in cas[:,0]:\n",
    "        if u in u_f: u_f[u] += 1\n",
    "        else: u_f[u] = 1\n",
    "            \n",
    "u_t = {}\n",
    "for cas in true_cascades:\n",
    "    for u in cas[:,0]:\n",
    "        if u in u_t: u_t[u] += 1\n",
    "        else: u_t[u] = 1\n",
    "        \n",
    "u_t_f = {}\n",
    "u_t_f.update(u_t)\n",
    "u_t_f.update(u_f)\n",
    "\n",
    "# --------------\n",
    "\n",
    "tot = 0.0\n",
    "for fake in fake_cascades:\n",
    "    tot += len(fake)\n",
    "print(tot)\n",
    "print(tot/len(fake_cascades))\n",
    "    \n",
    "# 1021 (avg size of fake cascades without intervention)\n",
    "# 905, 707, 179 (20, 50, 10)\n",
    "\n",
    "list_fake = [55694188, 42263843, 51406303, 1613744, 55272135, 55696103, 20468010, 12062772, 6004772, 5207724, 40208, 7494749, 38900860, 29012168, 9212253, 42946550, 4049583, 7405545, 39357, 27293990, 47294657, 30727658, 47732168, 52159242, 38972039, 32836210, 62022, 53932076, 37484955, 40906901, 14847426, 62047, 48439353, 38529727, 10243414, 2804617, 39387177, 9120036, 47866123, 47489548, 7609193, 1787533, 608347, 55657315, 55670766, 6454601, 23513871, 47741058, 27826144, 44442353, 37186191, 34140481, 48117808, 61292, 12326364, 11228024, 9022728, 2023955, 38361523, 11751139, 9404788, 49724208, 47913663, 55994964, 4070292, 55773805, 29521463, 2272182, 55977561, 44304477, 8414359, 135577, 42149683, 16222285, 42185160, 99697, 55918251, 20936857, 20376303, 1665263, 19049121, 17166687, 12068845, 49578583, 46161035, 35163914, 53273423, 55814726, 44044092, 16996691, 70791, 756, 41086244, 42053198, 36351, 44620283, 29401914, 17822, 8137344, 41310301]\n",
    "set_fake = set(list_fake[0:20])\n",
    "tot = 0.0\n",
    "for fake in fake_cascades:\n",
    "    for i, f in enumerate(fake[:,0]):\n",
    "        if int(f) in set_fake:\n",
    "            # print(\"broken\")\n",
    "            break\n",
    "    tot += i\n",
    "    # break\n",
    "print(tot)\n",
    "print(tot/len(fake_cascades))\n",
    "\n",
    "list_fake = [1751276, 40642400, 3089441, 43376598, 36020039, 2617568, 55778918, 55807571, 44097883, 5887002, 81419, 20669943, 2233, 14525664, 17822, 42460, 40002259, 47845816, 30812768, 24313765, 55870407, 23246779, 5515116, 20224270, 48317134, 10097798, 55875089, 27571772, 22572117, 25486749, 1799663, 55762954, 55976677, 73068, 1829550, 54861866, 37368977, 39470093, 5837040, 13468120, 6874742, 11400501, 3906745, 2723226, 20235544, 31441663, 46044235, 27344887, 22673672, 46383996, 17339739, 31328008, 88040, 5885871, 53932076, 55869547, 6680826, 55729750, 73076, 55431049, 22481177, 9464, 34457017, 5207724, 54877956, 19498012, 7, 40208, 8684187, 8017839, 20445938, 29012168, 21224591, 15643182, 2465273, 55741827, 38972039, 17716823, 42844183, 15275360, 44681162, 15685307, 23801369, 21383369, 24182643, 47757001, 25114298, 17906363, 16127469, 55718371, 27826144, 22468486, 39346177, 39046439, 12644262, 9458, 52340401, 55383382, 11209421, 1786837]\n",
    "set_fake = set(list_fake[0:100])\n",
    "tot = 0.0\n",
    "for fake in fake_cascades:\n",
    "    for i, f in enumerate(fake[:,0]):\n",
    "        if int(f) in set_fake:\n",
    "            # print(\"broken\")\n",
    "            break\n",
    "    tot += i\n",
    "    # break\n",
    "print(tot)\n",
    "print(tot/len(fake_cascades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Dynamics (Inferred edges test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': '11',\n",
    "          'figure.figsize': (4, 4),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "import pickle, sys\n",
    "\n",
    "# to_plot = False\n",
    "to_plot = True\n",
    "cascades_dict = pickle.load(open(\"../../main/pred_cas/fakeseeds_truediffma.pkl\", \"rb\"))\n",
    "saveimg_path = 'pred_cas_ma/fakeseeds_truediffma'\n",
    "\n",
    "for pltno, (seedset, sims) in enumerate(cascades_dict.items()): # [-2:-1]):\n",
    "    \n",
    "    print(\".............\")\n",
    "    print(\"Seedset:\", seedset)\n",
    "    \n",
    "    list_actives = []\n",
    "    maxlen = 0\n",
    "    for cas in sims:\n",
    "        u = cas[:, 0]\n",
    "        t = cas[:, 1]\n",
    "        time = -1\n",
    "        actives = []\n",
    "        for i in t:\n",
    "            if i > time:\n",
    "                time += 1\n",
    "                actives.append(1)\n",
    "            else:\n",
    "                actives[time] += 1\n",
    "        list_actives.append(actives)\n",
    "        if len(actives) > maxlen:\n",
    "            maxlen = len(actives)\n",
    "    print(\"Maxlength of simulated cascade:\", maxlen)\n",
    "#     if maxlen < 50:\n",
    "#         maxlen = 50\n",
    "    if maxlen < 100:\n",
    "        maxlen = 100\n",
    "    expected_cascade = np.zeros((len(list_actives), maxlen))\n",
    "    for i, act in enumerate(list_actives):\n",
    "        expected_cascade[i] = np.array(act + [0]* (maxlen-len(act)))\n",
    "\n",
    "    mean = np.mean(expected_cascade, 0)\n",
    "    std = np.std(expected_cascade, 0)\n",
    "    cum = 1.0* np.cumsum(mean)\n",
    "    cumnorm = cum/np.max(cum)\n",
    "    print(\"Final expected size of cascade:\", np.max(cum))\n",
    "    print(\"Max # tweets expected at any timestep:\", np.max(mean))\n",
    "    \n",
    "    if to_plot:\n",
    "        f = plt.figure()\n",
    "        x_pts = np.arange(maxlen)\n",
    "\n",
    "        ax1 = f.add_subplot(111)\n",
    "        # line1 = ax1.bar(x_pts, mean, yerr=std, color='indianred', label=\"expected\")\n",
    "        line1 = ax1.bar(x_pts, mean, color='indianred', label=\"expected\")\n",
    "        ax1.fill_between(x_pts, mean-std, mean+std,  color='pink',alpha=0.8, hatch = '/')\n",
    "        # ax1.set_xticks(np.arange(0, maxlen+1, 10))\n",
    "        # ax1.set_ylim(0, 20)\n",
    "        ax1.set_xticks(np.arange(0, maxlen+1, 20))\n",
    "        ax1.set_ylim(0, 40)\n",
    "        \n",
    "        ax2 = f.add_subplot(111, sharex=ax1, frameon=False)\n",
    "        line2 = ax2.fill_between(x_pts, cumnorm, color='steelblue', alpha=0.2, label=\"expected\")\n",
    "        # ax2.set_xticks(np.arange(0, maxlen+1, 10))\n",
    "        ax2.set_xticks(np.arange(0, maxlen+1, 20))\n",
    "        ax2.set_ylim(0, 1+0.05)\n",
    "        ax2.yaxis.tick_right()\n",
    "\n",
    "        plt.legend((line1, line2), ('Exp # Tweets', 'Cum. Freq.'), loc='upper left')\n",
    "        plt.xlabel('Timesteps', fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        if saveimg_path:\n",
    "            plt.savefig('{}{}.png'.format(saveimg_path, pltno))\n",
    "\n",
    "\n",
    "# ('Seedset:', '22225065')\n",
    "# ('Maxlength of simulated cascade:', 13)\n",
    "# ('Final expected size of cascade:', 2.4800000000000004)\n",
    "# ('Max # tweets expected at any timestep:', 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mic",
   "language": "python",
   "name": "mic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
